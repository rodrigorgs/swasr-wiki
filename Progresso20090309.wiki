= Progresso =
== Redes complexas em software ==
Eu li mais de 10 artigos que estudam a estrutura de programas de computador sob a luz da teoria das redes complexas. Alguns artigos estudam a rede formada pelas dependências entre pacotes Debian, pacotes FreeBSD etc, e outros estudam sistemas isoladamente. Destes últimos, há estudos sobre a estrutura de programas escritos linguagens estruturadas, como C, e em linguagens orientadas a objetos, como C++, Java e Smalltalk. Note que Smalltalk é uma linguagem com tipificação dinâmica. Há ainda estudos sobre as referências entre objetos, em tempo de execução. Em todos os casos os pesquisadores encontraram redes livres de escala. Ou seja, a distribuição do número de arestas por vértice segue uma lei de potência (power law).
Estudos sobre características não-estruturais, como a distribuição de quantidade de métodos por classe ou a quantidade de classes por pacotes, também encontraram leis de potência.
Outra coisa interessante são os motifs, ou motivos. Motivos são padrões de vértices e arestas. Descobriram que há certos padrões que aparecem em redes de software com uma freqüência muito maior do que é de se esperar se as redes fossem geradas ao acaso.
O coeficiente de clustering de um vértice mede a quantidade de triângulos (ciclos de tamanho 3) dos quais o vértice participa. Em outras palavras, o coeficiente de clustering responde à pegunta: os meus amigos são amigos entre si? Como já vimos, redes de software possuem um alto coeficiente de clustering médio (muito maior do que o esperado em redes aleatórias) e além disso, o coeficiente é inversamente proporcional ao grau do vértice. Esse tipo de distribuição é um indicador de que a rede possui uma estrutura hierárquica. Observando essa distribuição podemos concluir que vértices com muitas ligações conectam vértices que não estão ligados entre si. Uma possível interpretação os hubs tendem a conectar conjuntos de vértices pouco coesos, formados por vértices com funções distintas na rede.
== Clustering ==
A tarefa de detectar módulos em redes software pode aproveitar insights de várias linhas de pesquisa. Em engenharia de software é recuperação de arquitetura. Em física é detecção de comunidades. E em mineração de dados é clustering mesmo. Podemos tirar lições valiosas de todas essas linhas de pesquisa.
No início de fevereiro eu li um artigo de física sobre detecção de comunidades. O que eles chamam de comunidade é o que nós chamamos de módulo. O artigo afirma que pra avaliar algoritmos de detecção de comunidade o ideal é que tivéssemos várias redes cuja estrutura de comunidades fosse conhecida, mas infelizmente esse não é o caso. Os autores então propõem usar redes geradas por computador, com uma estrutura de comunidades embutida. A partir daí eles apresentam um modelo de redes com comunidade embutida e avaliam dois algoritmos usando redes geradas por esse modelo.
Uma coisa interessante de usar modelos é que eu posso entender melhor as fraquezas dos algoritmos de clustering. Dá pra estudar como o desempenho dos algoritmos se altera com a variação dos parâmetros do modelo. O artigo mostra que, quando aumenta o número de arestas que ligam comunidades distintas, os algoritmos tendem a errar mais.
Depois disso eu vi um artigo da área de biologia que usa as mesmas idéias. Outra idéia que ele traz é pegar uma rede cujos módulos sejam conhecidos e então adicionar e remover arestas pra ver como os algoritmos se comportam.
== Estatística ==
"Power law distributions in empirical data"
Muitos estudos sobre redes de software usam ferramentas estatísticas inadequadas.
A reta não é uma boa curva de regressão dos gráficos de distribuição de graus. O fato é que existem várias distribuições chamadas de cauda longa, cujo gráfico log-log é aproximadamente uma reta, e são caracterizadas pela presença de alguns elementos cujo valor está muito acima do valor médio. Essas distribuições incluem lei de potência (power law), lei de potência com cutoff exponencial, stretched exponential, double pareto e lognormal.
Na minha análise preliminar eu fiz regressão linear no gráfico de distribuição de graus usando o método dos mínimos quadrados a fim de estimar o expoente da distribuição e então calculei R² a fim de mostrar que a distribuição realmente se encaixava numa reta. Descobri que esse método assume que a distribuição possui certas características que não se aplicam à lei de potência. O mais indicado para estimar o expoente é usar o método de maximum likelihood estimation. E um valor alto de R² não quer dizer a melhor distribuição que se encaixa nos dados é a lei de potência, já que existem outras distribuições que poderiam fornecer R² igualmente alto ou maior.
Dificilmente todos os pontos vão se encaixar em uma distribuição, então normalmente as análises consideram apenas uma região do gráfico, por exemplo, o lado direito (a cauda). O teste estatístico goodness-of-fit ajuda a determinar a região que melhor se encaixa em uma distribuição.
A função de distribuição cumulativa complementar -- P(X >= x) -- é usada para reduzir os efeitos de pontos fora-da-curva (outliers) na análise. No caso de leis de potência, existe uma relação algébrica entre o coeficiente angular da reta da função cumulativa e o coeficiente da função não-cumulativa, P(X = x).
== Recuperação de arquitetura ==
Só li no ano passado.
= Dúvidas =
== Autocríticas ==
(ver críticas ao artigo Benchmark....)
== Escopo ==
Análise + modelagem de evolução?
Avaliação de recuperação de arquitetura traz o trabalho para um full circle.
== Comentários Externos ==
Preciso de uma definição de cluster.